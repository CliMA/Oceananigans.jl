using Base: @propagate_inbounds

using OffsetArrays
using JLD2

using Oceananigans.Architectures
using Oceananigans.Grids
using Oceananigans.Fields
using Oceananigans.Fields: show_location

import Oceananigans: short_show

struct FieldTimeSeries{X, Y, Z, K, A, T, N, D, G, B, χ} <: AbstractDataField{X, Y, Z, A, G, T, N}
                   data :: D
           architecture :: A
                   grid :: G
    boundary_conditions :: B
                  times :: χ
                   name :: String
               filepath :: String

    function FieldTimeSeries{X, Y, Z}(backend::K, data::D, arch::A, grid::G, bcs::B, times::χ, name, filepath, N) where {X, Y, Z, K, D, A, G, B, χ}
        T = eltype(grid)
        return new{X, Y, Z, K, A, T, N, D, G, B, χ}(data, arch, grid, bcs, times, name, filepath)
    end
end

# Include the time dimension.
@inline Base.size(fts::FieldTimeSeries) = (size(location(fts), fts.grid)..., length(fts.times))

@propagate_inbounds Base.getindex(f::FieldTimeSeries{X, Y, Z, InMemory}, i, j, k, n) where {X, Y, Z} = f.data[i, j, k, n]

FieldTimeSeries(filepath, name; architecture=CPU(), backend=InMemory()) =
    FieldTimeSeries(filepath, name, architecture, backend)

function FieldTimeSeries(filepath, name, architecture, backend::InMemory)
    file = jldopen(filepath)

    grid = file["serialized/grid"]
    Hx, Hy, Hz = halo_size(grid)

    iterations = parse.(Int, keys(file["timeseries/t"]))
    times = [file["timeseries/t/$i"] for i in iterations]

    LX, LY, LZ = file["timeseries/$name/serialized/location"]

    Nt = length(times)
    data_size = size(file["timeseries/$name/0"])
    underlying_data = zeros(data_size..., Nt)
    data = OffsetArray(underlying_data, -Hx, -Hy, -Hz, 0)

    for (n, iter) in enumerate(iterations)
        data.parent[:, :, :, n] .= file["timeseries/$name/$iter"]
    end

    bcs = file["timeseries/$name/serialized/boundary_conditions"]

    close(file)

    return FieldTimeSeries{LX, LY, LZ}(backend, data, architecture, grid, bcs, times, name, abspath(filepath), ndims(data))
end

function FieldTimeSeries(filepath, name, architecture, backend::OnDisk)
    file = jldopen(filepath)

    grid = file["serialized/grid"]
    iterations = parse.(Int, keys(file["timeseries/t"]))
    times = [file["timeseries/t/$i"] for i in iterations]

    data = nothing
    LX, LY, LZ = file["timeseries/$name/serialized/location"]
    bcs = file["timeseries/$name/serialized/boundary_conditions"]

    close(file)

    return FieldTimeSeries{LX, LY, LZ}(backend, data, architecture, grid, bcs, times, name, abspath(filepath), 4)
end

Base.getindex(fts::FieldTimeSeries{X, Y, Z, InMemory}, n::Int) where {X, Y, Z} =
    Field((X, Y, Z), fts.architecture, fts.grid, fts.boundary_conditions, fts.data[:, :, :, n])

function Base.getindex(fts::FieldTimeSeries{X, Y, Z, OnDisk}, n::Int) where {X, Y, Z} =
    file = jldopen(fts.filepath)
    iter = keys(file["timeseries/t"])[n]
    raw_data = file["timeseries/$(fts.name)/$iter"]
    close(file)

    return Field((X, Y, Z), fts.architecture, fts.grid, fts.boundary_conditions, offset_data(raw_data, fts.grid, fts.location))
end

backend_str(::InMemory) = "InMemory"
backend_str(::OnDisk) = "OnDisk"

short_show(fts::FieldTimeSeries{X, Y, Z, K}) where {X, Y, Z, K} =
    string("$(join(size(fts), "×")) FieldTimeSeries{$(backend_str(K()))} located at $(show_location(fts))")

Base.show(io::IO, fts::FieldTimeSeries{X, Y, Z, K, A}) where {X, Y, Z, K, A} =
    print(io, "$(short_show(fts))\n",
          "├── filepath: $(fts.filepath)\n",
          "├── architecture: $A\n",
          "└── grid: $(short_show(fts.grid))")
